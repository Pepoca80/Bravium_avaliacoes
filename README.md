Pedro Henrique Chaves Lopo
# üõçÔ∏è An√°lise de Sentimentos em Reviews de E-commerce

## üéØ Objetivo do Projeto

Este projeto utiliza t√©cnicas de Processamento de Linguagem Natural (PLN) e Machine Learning para construir um sistema capaz de classificar automaticamente reviews de produtos de um e-commerce como **positivos** ou **negativos**. O objetivo final n√£o √© apenas prever o sentimento, mas tamb√©m extrair insights acion√°veis que possam guiar decis√µes de neg√≥cio, como identificar os principais motivos de satisfa√ß√£o e insatisfa√ß√£o dos clientes.

## üöÄ Tecnologias Utilizadas

* **Python 3.x**
* **Pandas & NumPy:** Para manipula√ß√£o e an√°lise de dados.
* **Matplotlib & Seaborn:** Para visualiza√ß√£o de dados.
* **Scikit-learn:** Para pr√©-processamento, modelagem de Machine Learning e avalia√ß√£o.
* **Jupyter Notebook:** Como ambiente de desenvolvimento e apresenta√ß√£o da an√°lise.

## üìñ Decis√µes de Projeto (Fluxo Linear)

Cada passo do projeto envolveu decis√µes importantes para garantir a qualidade e a relev√¢ncia do resultado final. A seguir, o fluxo de decis√µes em ordem cronol√≥gica:

### 1. Defini√ß√£o do Problema e da M√©trica Alvo

A primeira e mais crucial decis√£o foi transformar um problema de classifica√ß√£o de 5 estrelas em uma **classifica√ß√£o bin√°ria**.

* **Decis√£o:** Mapear as notas de 1 a 5 para as classes "positivo" e "negativo".
* **Justificativa:** Para o neg√≥cio, a distin√ß√£o mais importante √© saber se a experi√™ncia do cliente foi boa ou ruim. Uma classifica√ß√£o bin√°ria √© mais direta para gerar alertas e a√ß√µes corretivas. A regra de neg√≥cio definida foi:
    * **Notas 4 e 5 ‚Üí `positivo`**: Indicam satisfa√ß√£o.
    * **Notas 1, 2 e 3 ‚Üí `negativo`**: Indicam algum n√≠vel de insatisfa√ß√£o que merece aten√ß√£o.

### 2. Fonte de Dados

* **Decis√£o:** Utilizar o dataset p√∫blico [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce), focando no arquivo `olist_order_reviews_dataset.csv`.
* **Justificativa:** √â um dataset robusto, com um grande volume de reviews reais em portugu√™s, o que o torna ideal para treinar um modelo de an√°lise de sentimento para o mercado brasileiro.

### 3. Pr√©-processamento e Limpeza de Texto

* **Decis√£o:** Criar uma fun√ß√£o de pr√©-processamento (`preprocess_text`) para padronizar todo o texto dos reviews. As etapas foram:
    1.  Combinar t√≠tulo e mensagem do review para ter o m√°ximo de contexto.
    2.  Converter todo o texto para min√∫sculas.
    3.  Remover toda a pontua√ß√£o.
    4.  Remover n√∫meros.
    5.  Remover espa√ßos em branco extras.
* **Justificativa:** Modelos de Machine Learning n√£o entendem texto bruto. Esta limpeza garante que palavras como "Produto", "produto" e "produto!" sejam tratadas como a mesma coisa, reduzindo a complexidade e melhorando a performance do modelo.

### 4. Engenharia de Features (Vetoriza√ß√£o de Texto)

* **Decis√£o:** Utilizar a t√©cnica **TF-IDF (Term Frequency-Inverse Document Frequency)** para converter o texto pr√©-processado em vetores num√©ricos.
* **Justificativa:** O TF-IDF foi escolhido em vez de uma simples contagem de palavras (CountVectorizer) porque ele atribui um peso maior √†s palavras que s√£o importantes para um review espec√≠fico, mas n√£o t√£o comuns em todos os reviews. Isso ajuda o modelo a focar nos termos mais distintivos.
* **Hiperpar√¢metros:**
    * `ngram_range=(1, 2)`: Para que o modelo capture n√£o apenas palavras isoladas ('ruim'), mas tamb√©m express√µes de duas palavras ('n√£o recomendo', 'muito bom').
    * `max_features=5000`: Para limitar o vocabul√°rio √†s 5000 palavras mais relevantes, controlando a dimensionalidade e evitando overfitting.

### 5. Modelagem e Treinamento

* **Decis√£o:** Treinar e comparar tr√™s algoritmos de classifica√ß√£o diferentes: `Logistic Regression`, `Random Forest` e `Multinomial Naive Bayes`.
* **Justificativa:** N√£o h√° um "melhor modelo" para todos os problemas. Comparar diferentes algoritmos permite selecionar empiricamente aquele que melhor se adapta a este dataset espec√≠fico.
* **Valida√ß√£o:** A valida√ß√£o cruzada (`cross_val_score` com 5 folds) foi utilizada para obter uma estimativa mais robusta e confi√°vel da performance de cada modelo, evitando que o resultado dependa de uma √∫nica divis√£o sorteada de treino/teste.

### 6. Avalia√ß√£o

* **Decis√£o:** Utilizar a **Acur√°cia** como m√©trica principal para comparar os modelos, mas tamb√©m analisar o **Relat√≥rio de Classifica√ß√£o (Precision, Recall, F1-Score)** e a **Matriz de Confus√£o** para o melhor modelo.
* **Justificativa:** A acur√°cia oferece uma vis√£o geral r√°pida do desempenho. No entanto, analisar Precision e Recall √© fundamental para entender como o modelo se comporta em cada classe (positiva e negativa) e identificar se ele est√° enviesado para uma delas.

### 7. An√°lise de Insights e Explicabilidade (XAI)

* **Decis√£o:** Ir al√©m da classifica√ß√£o e implementar funcionalidades para extrair insights de neg√≥cio.
* **Justificativa:** O valor real de um modelo de IA no contexto de neg√≥cios n√£o est√° apenas na predi√ß√£o, mas na capacidade de explicar o porqu√™ e guiar a√ß√µes. Por isso, foram desenvolvidas fun√ß√µes para:
    1.  **Identificar Palavras-Chave:** Mostrar quais termos mais influenciam uma decis√£o positiva ou negativa.
    2.  **Categorizar por Temas:** Agrupar os feedbacks em categorias como "Entrega", "Qualidade", etc.
    3.  **Criar um Dashboard de Satisfa√ß√£o:** Calcular KPIs para cada tema, permitindo que a √°rea de neg√≥cio identifique rapidamente os pontos fortes e fracos da opera√ß√£o.

## ‚öôÔ∏è Como Executar o Projeto

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    ```
2.  **Navegue at√© a pasta do projeto:**
    ```bash
    cd seu-repositorio
    ```
3.  **Instale as depend√™ncias:**


## üìä Resultados e Conclus√µes

Ap√≥s o treinamento e avalia√ß√£o, o modelo **[Nome do Melhor Modelo, ex: Logistic Regression]** foi selecionado como o de melhor performance, atingindo uma acur√°cia de **[Valor da Acur√°cia, ex: 94.2%]** no conjunto de teste.

A an√°lise de insights revelou que os principais drivers de reviews negativos est√£o relacionados a **[Ex: atrasos na entrega e qualidade do produto]**, enquanto a **[Ex: rapidez na entrega e o bom custo-benef√≠cio]** s√£o os pontos mais elogiados pelos clientes.

